---
title: " "
output: pdf_document
header-includes:
  - \usepackage{float}
  - \usepackage{sectsty}
---

# Introduction

## Elements qui n'entrent pas dans ma structure de base mais voir si et comment les intégrer dans l'intro

## Problème lié au stat en général

### J'ai l'impression que ça parle surtout des stat plus complexes mais au cas où ça servirait plus tard...
Parmi les milliers d'étudiants diplomés chaque année en psychologie au Canada, la plupart n'ont pris qu'un seul cours de statistiques et ont des connaissances très limitées en ce qui concerne l'analyse de données [@golinski_expanding_2009]. De plus, parmi les doctorants, beaucoup n'ont pas les connaissances requises pour faire face à la complexité des méthodes statistiques modernes qui apparaissent en psycho et doivent mobiliser des ressources pour les aider...  
(1) les psys qui se spécialisent dans une méthode quanti (ex.: modèles d'équation structurée)    
(2) des consultants (appartenant souvent à (1))  
(3) des articles statistiques.  Mais ces derniers semblent assez peu utilisés par les chercheurs. En tout cas s'ils les utilisent, ils les citent très peu dans leurs références pour justifier leurs choix (cf. article de @mills_quantitative_2010: le mode du nombre de citation méthodo dans les articles de recherche appliqués est 0, et la médiane vaut 1... ). Dans l'autre sens, on constate que les articles méthodos sont généralement peu cités, et ils le sont encore 3 fois moins par les chercheurs appliqués que par les autres méthodologistes [@mills_quantitative_2010, p.56]. 

RELIRE CECI POUR VOIR QUOI FAIRE DE CETTE IDEE: les tests conventionnels (tests t, ANOVA et régression) sont faussement simples, car ils reposent sur des notions importantes et complexes telles que la distribution d'échantillonnage et la p-valeur, notions malheureusement encore mal comprises par nombreux chercheurs. Bien comprendre celle-ci requiert du temps et de la patience. C'est un travail de longue haleine. Il m'a fallu des années de simulations et d'études pour réellement comprendre des tests qui semblent aussi simples que le test t, alors que je suis passionnée. Cela montre à quel point il est important pour les psychologues que des personnes prennent le temps de vulgariser le travail pour eux. Des outils comme Jamovi sont mis en place afin de faciliter la vie des chercheurs. Pour continuer à alimenter et mettre à jour ces outils le mieux possible, d'une manière pas trop douloureuse pour le chercheur lambda, il est important que des méthodologistes continuent à jouer le pont entre psychologues et statisticiens comme j'essaye de le faire.

### Comment écrire/transmettre l'info aux psys
Un consultant doit pouvoir parler de langage des psycs, c'est-à-dire décrire et expliquer les méthodes requises d'une manière compréhensible pour les clients [@golinski_expanding_2009]. Est-ce bien de demander à des mathématiciens/Statisticiens d'enseigner les stat aux psy's? Par forcément, car un psychologue spécialisé en méthodo quanti sera plsu à m^mee de comprendre les procédures et méthodes requises par les psys (ex. de la question de la taille d'effet qui n'intéresse pas vraiment les statisticiens; @golinski_expanding_2009). 

### Pourquoi un article ne suffit pas et que les logiciels comptent (ex. Jamovi, R...)
On est en droit de questionner l'impact réel des publications méthodologiques, pour 2 raisons, d'après @mills_quantitative_2010:  
(1) Les chercheurs appliqués sont noyés sous les articles dans leur domaine d'expertise si bien que cela limite le temps dont ils disposent pour se consacrer aux articles méthodologiques.   
(2) malgré que des nouvelles méthodes sont disponibles, les chercheurs continuent à opter pour des tests traditionnels et familiaux (mais souvent inappropriés).  

### Recommandations générales

@mills_quantitative_2010:  
- au moins un reviewer compétant pour analyser le caractère approprié des méthodes stat  
- que les éditeurs/reviewers encouragent l'usage d'article de méthodo
--> interesting, mais réaliste? La proportion de méthodologistes parmis les psychologues n'est pe pas assez élevée... Ou alors il faut vraiment de l'interdisciplinarité!

## Début de la vraie intro

Les statistiques jouent un rôle très important dans le parcours des chercheurs en psychologie, et des psychologues de manière générale. On attend d'eux qu'ils soient capables de produire des connaissances, fondées sur des preuves scientifiques (et non sur des croyances et opinions), et également de comprendre et évaluer les recherches menées par d'autres [@haslam_research_2014]. Or, les connaissances statistiques s'avèrent fondamentales pour comprendre, planifier et analyser une recherche [@howitt_understanding_2017; @everitt_statistics_2001]. (CAR L ANALYSE QUANTI DOMINE SUR L ANALYSE QUALI... VOIR SI JE LE PLACE). Il est donc tout naturel que les statistiques fassent partie intégrante du cursus de formation des psychologues. 

Malgré un développement inouï de méthodes statistiques de plus en plus complexes au cours des 50 dernières années (méta-analyses, équations structurelles, modèles linéaires hiérarchiques...@sharpe_why_2013), les ANOVA et les régressions restent prédominantes en psychologie. Ces test se retrouvent au choeur des programmes de statistiques au sein des pratiquement toutes les facultés de psychologie (vu pour le Canada et les USA en 2008) [@aiken_doctoral_2008; @golinski_expanding_2009]. De plus, on les retrouve très fréquemment dans la littérature scientifique.
- Parmis 486 articles publiés en 2000 dans des journaux populaire de psychologies ($Child Development; Journal of Abnormal Psychology; Journal of Consulting and Clinical Psychology; Journal of Experimental Psychology: General; Journal of Personality and Social Psychology$), 140 ($\approx 29 \%$) ont mené au moins une ANOVA à un ou plusieurs facteurs [@golinski_expanding_2009]; 
- Sur un total de 282 études reportées dans *Social Psychological $\&$ Personality Science* entre avril 2015 et avril 2016, 97 ($\approx 34 \%$) utilisaient un test-$t$ [@delacre_why_2017].   
- Quant aux ANOVA à un facteur, nous en avons trouvé dans 14% des 116 articles publiés en 2016 dans le *Journal of Personality and Social psychology* [@delacre_taking_2019].   

La dominance des ANOVA et régressions ne date pas d'hier... @nunnally_place_1960 en faisait déjà le constat il y a plus de 50 ans. De plus, on ne compte plus les livres d'introductions aux statistiques pour psychologues faisant mention de ces tests (en citer quelques uns bien connus). essayer de trouver des livres qui en parlent théoriquement et d'autres qui les mettent en lien avec des logiciels connus.

Si d'aucun admettent assez facilement que la plupart des étudiants diplômés en psychologie n'ont pas les connaissances suffisantes en analyse de données pour aborder des outils aussi complexes que les SEM et modèles linéaires hiérarchiques *Parmi les milliers d'étudiants diplomés chaque année en psychologie au Canada, la plupart n'ont pris qu'un seul cours de statistiques et ont des connaissances très limitées en ce qui concerne l'analyse de données [@golinski_expanding_2009]*, beaucoup croient que leurs étudiants ont une bonne maîtrise des tests t et des ANOVA. Par exemple, parmi les professeurs interrogés en 2008 par @aiken_doctoral_2008 au sein de 201 départements, professeurs conférant des programmes de doctorat en psychologie aux USA et au Canada, presque tous (entre 80% et 100%) affirmaient que la plupart (si pas tous) leurs étudiants étaient capable de réaliser une ANOVA à un ou plusieurs facteurs (que ce soit l'approche a priori ou post hoc). Mais n'est-ce pas un peu trop optimiste?

## La manière dont l'ANOVA et les tests $t$ sont utilisés en psychologie.

Les tests t et ANOVA ont la fausse réputation d'être simples et maîtrisés par la plupart. Pourtant, encore aujourd'hui, des nombreux manquements dans l'usage de ces tests peuvent être soulignés. C'est ce que nous tentons de faire à travers cette thèse. 

Très classiquement, lorsqu'on compare 2 ou plus de 2 groupes définis par les modalités d'un ou plusieurs facteurs catégoriels, on "résume" la distribution des scores au sein de chaque groupe par un indicateur de tendance centrale (la moyenne), et on postule que tous les échantillons sont extraits de populations dont les moyennes sont identiques ($H_0: \mu_1=\mu_2=...=\mu_k$). On réaliste un test $t$ (de Student) ou une ANOVA (de Fisher) et Si la $p$-valeur est inférieure au risque alpha, on conclut au rejet de l'hypothèse nulle. 

Biensûr, la moyenne n'est pas le seul indicateur de tendance centrale et des tentatives ont été faites pour introduire d'autres indicateurs dans les tests (citer Wilcox par exemple), mais ces alternatives ont eu nettement moins de succès [@keselman_statistical_1998]. (Remarque: @keselman_statistical_1998 ajoute que les post hoc de Tukey sont les préférés aussi). Et même en se limitant aux comparaisons de moyennes, il existe des alternatives au test $t$ de Student et à l'ANOVA de Fisher (cf. tests robustes), mais leur adoption est très compliquée. 

### Limite 1: conditions d'application

Les tests statistiques conduiront à une interprétation valide à condition de respecter une ou plusieurs conditions d'application. Un non respect des conditions d'application pourra sérieusement affecter le taux d'erreur de types I et II des tests. Pourtant, ces conditions ne sont que peu ou pas vérifiées [@hoekstra_are_2012]. 

- @keselman_statistical_1998: sur 61 articles contenant des designs dans lesquels des échantillons indépendants étaient définis par un seul facteur (between-subjects univariate designs, 13 n'ont pas donné d'information relatives aux écart-types. Parmi les autres, il y avait de l'hétéroscédasticité. En tout, moins d'un article sur 5 se préoccupait des violations possibles des conditions d'application, et lorsqu'ils le faisaient, ils s'inquiétaient surtout de la condition de normalité (moins de l'hétéroscédasticité), et ce malgré le fait que pourtant, des violations de cette conditions sont bien plus dommageables!   
- voir dans mes 2 articles sur le Welch, je donne des exemples aussi de ça
- @golinski_expanding_2009: parmi 140 articles publiés dans plusieurs revues célèbres qui utilisaient l'ANOVA (voir plus haut), très peu vérifiaient les conditions d'application. *"It is interesting that, of the 11 articles that mentioned the normality assumption, 10 found distributions thate were nonnormal. Althought it is possible that the remaining articles taht did not mention th enormality assumptiona ll found noevidence of nonnormality, it seems highly unlikely given that Micceri (1989) who examined 440 variables from pubmished articles in educaiton and psychology, found that 84% showed moderate to extreme skew"*. En ce qui concerne l'homogénéité des variances, seulement 3 mentionnaient l'hypothèse d'homogénéité des variances, alors que parmis les 65 articles donnant l'info sur les variances de groupe, 27 avaient un SDR de plus de 2 (dans une étude, le SDR était même de 104), et que la plupart d'entre elles avaient des designs non balancés.     

--> POURQUOI ELLES NE LE SONT PAS? 

Ce constat est loin d'être récent. Par exemple, @keselman_statistical_1998 mettaient en évidence le fait que les chercheurs tendaient à utiliser des tests non robustes aux violations des conditions d'application, sans vérifier au préalable si ces conditions étaient respectées. 

Même lorsqu'un chercheur souhaite vérifier les conditions d'application, il reste confronté à plusieurs problèmes. 

1. Les conditions reposent sur les paramètres de *population* et non sur les paramètres d'échantillon. Or, ces paramètres de population ne sont pas connus (s'ils l'étaient, on n'aurait pas besoin des statistiques) [@hoekstra_are_2012].
2. Les conditions sont souvent très irréalistes. 

Il existe des tests dit "tests robustes" qui ne sont théoriquement pas affectés par une violation des conditions d'application, mais ces derniers ne sont que peu ou pas utilisés [@sharpe_why_2013]

Comment améliorer les pratiques de recherche facilement, d'une manière qui assure que les chercheurs appliqueront les conseils? En proposant des switchs faciles. L'usage des tests de Welch est un bel exemple de switch facile. Ceci dit, ce n'est pas parcpe que le switch est facile qu'il est forcément fait: @keselman_statistical_1998 écrit ceci: "Despite these repeated cautionary notes, behavioral science researchers have clearly not taken this mesasge to heart. It is strongly recommended that test procedures that have been desiged specifically for use in the presence of variance heterogeneity and/or nonnormality be adopted on a routine basis" (p.358).
Rem.: ils parlent d'un article de Lix et al. (1996) qui mentionne des packages qui permettent de le faire mais l'article est introuvable sur google scholar. L'open access est une des clés pour moi. w

ARTICLE1
ARTICLE2.

### Limite 2: hypothèse nulle

2) comme déjà mentionné, l'hypothèse nulle est l'absence d'effet. On en reste sur la nil-hypothesis. Du coup, un effet significatif n'a pas vraiment de valeur. En réponse à ce problème, on a écrit deux articles:

- On peut commencer par ajouter une information sur les tailles d'effets (mais du coup ça n'oblige pas à réfléchir à l'avance à l'effet qui nous intéresse)

Dans la revue de @keselman_statistical_1998, ils mentionnent que les tailles d'effet ne sont pratiquement jamais reportées malgré les recommandations du panuel de l'APA (1994) (et qu'elles ne sont fournies qu'en cas d'effet significatif). 

- On peut aussi faire des tests plus informatifs (tests d'équivalence et/ou tests d'effets minimaux). 

## Pourquoi jusque là la sauce n'a pas pris?

Je suis loin d'être la première à signaler tt ça. Ce qui manque encore dans mon plan d'introduction, c'est que je dois encore trouver le moyen de montrer en quoi mes articles sont une plus-value, ce qu'ils apportent.
2) Parler des packages, des applications Shiny, etc.

D'aucun on fait le constat d'un fossé entre les méthodes inférentielles recommandées dans la littérature scientifique et les techniques réellement utilisées par les chercheurs appliqués [keselman_statistical_1998]. 

PARLER DES DIFFERENTES REVUES DE LITTERATURE QUI LE DISENT. 

Qu'est-ce qui pourrait expliquer cela? 
1) @sharpe_why_2013: lack of awareness (p.573) Manque de conscience des développements dans le domaine?  
2) @sharpe_why_2013: journal edotors (p.573) Les éditeurs ne poussent pas assez? --> Pas convaincue que ça m'intéresse  
3) @sharpe_why_2013: Publish or perish? (p.574) je ne comprends mm pas en quoi c'est un argument  
4) @sharpe_why_2013: Software (p.574) --> aaahh! Certaines pratiques comme les équations structurelles et les analyses de puissance ont été facilitées par des software comme gpower. Cela explique leur popularité. En ce qui concerne les statistiques plus robustes, par contre, elles ont moins de succès car non dispo dans les softwares dispo. Les gens veulent juste qu'on leur dise où cliquer pour avoir le test qu'ils veulent! C'est triste mais faut faire avec (à mon avis).   
5) @sharpe_why_2013: inadequate education (p.574)  
6) @sharpe_why_2013: mindset: facteurs psychologiques t.q. la peur de dévier des pratiques courantes (comme si on n'allait pas être publié si on ne faisait pas comme tlm).  


Anecdote: les chercheurs font souvent l'erreur de croire qu'il faut vérifier la normalité de la VD en faisant une régression. Dans SPSS, il est assez complexe de le faire car il faut d'abord calculer les résidus, ce qui implique de comprendre que les tests t et ANOVA sont des cas particuliers de régression, puis ensuite a posteriori représenter graphiquement les résidus. C'est chronophage et complexe. Dans Jamovi, par contre, la vérification de la normalité des résidus est automatiquement réalisée lorsqu'on fait un test t. Le rôle des méthodologistes, à mon sens, est de prémacher le travail, pour permettre à d'autres de créer des outils conçus pour améliorer les pratiques de recherche. à partir du moment où c'est automatiquement fait correctement, il devient moins problématique que les psychologues maîtrisent le détail. Débarassés de ces questions, ils pourront peut-être alors plus se focaliser sur l'important pour mieux comprendre et interpréter les résultats de leur tests: càd comprendre la distribution d'échantillonnage, dont pratiquement tt découle.


