---
title: ''
output: pdf_document

header-includes:
  - \usepackage{xcolor}
  - \usepackage{bm}
---

# Discussion générale et conclusion

## Résumé de la thèse
A travers cette thèse, nos objectifs de départ étaient (1)	d’identifier des manquements dans les pratiques actuelles des chercheurs, via des analyses d’articles publiés dans des revues de psychologie ;  (2)	de réaliser des simulations, en vue de montrer l’impact de ces pratiques et (3)	de proposer des recommandations pour les améliorer.  

Dans un premier temps, nous nous sommes focalisés sur l'usage des statistiques $t$ de Student, $F$ de Fisher et $d$ de Cohen, soit des mesures communément utilisés par les chercheurs en psychologie, en vue de comparer les moyennes de deux ou plusieurs groupes de sujets indépendants, et qui reposent sur les conditions que des résidus, indépendants et identiquement distribués, soient extraits d'une distribution normale et que les variances des populations dont sont extraits chaque groupe soient identiques (soit la condition d'homogénéité des variances). Comme nous l'avons théoriquement décrit, il existe toute une série d'arguments qui permettent de remettre en cause la crédibilité des conditions statistiques de normalité (comme la présence de sous-populations définies par des facteurs non identifiés dans le design, l'étude de mesures bornées, telle(s?) que le temps qui ne peut prendre des valeurs négatives, ou encore le fait qu'un traitement est susceptible de modifier la forme des distributions étudiées) et d'homogénéité des variances (comme l'étude de groupes pré-existants à l'expérience, définis par des variables telles que le genre ou l'origine ethnique\footnote{Dans ce cas, les sujets ne sont pas répartis aléatoirement entre les groupes. L'hétérogénéité des variances entre les groupes et dès lors le résultats de la violation de la condition méthodologique d'indépendance des résidus.}, ou encore le fait qu'un traitement, qu'il soit expérimental ou quasi-expérimental, est susceptible d'agir sur tous les paramètres d'une distribution, incluant sa variance), dans de nombreux domaines de la psychologie. Conformément à nos objectifs de départ, nous avons réalisé des simulations Monte Carlo en vue de montrer les conséquences réelles de la violation des conditions de normalité et d'homogénéité des variances, et de comparer respectivement les statistiques $t$ de Student (chapitre 2), $F$ de Fisher (chapitre 3) et $d$ de Cohen (chapitre 4) à des alternatives plus robustes en cas de violation de la condition d'homogénéité des variances.\footnote{Comme expliqué en introduction, nous nous sommes principalement focalisés sur la condition d'homogénéité des variances compte tenu, d'abord, de la forte résistance de la part des chercheurs à l'égard des tests comparant d'autres indicateurs de tendance centrale que la moyenne et ensuite, du fait qu'un écart à la condition d'homogénéité des variances affectera bien plus les taux d'erreur de type $I$ et $II$ des statistiques $t$ de Student, $F$ de Fisher et $d$ de Cohen qu'un écart à la condition de normalité.} \color{blue} Les avancées récentes en termes d'informatique nous ont permis d'étendre les travaux déjà engagés en ce sens par de nombreux auteurs, grâce à des simulations intensives, avec 1,000,000 d’itérations pour un nombre très vaste de scénarios, variant en fonction d'un ensemble de paramètres connus pour jouer un rôle clé sur les taux d'erreur de type I et II du test $t$ de Student. \color{black} Il en est principalement ressorti que de manière consistante avec nos attentes théoriques, lorsque les deux échantillons comparés sont de même taille, le test $t$ de Student est robuste aux violations de la condition d'homogénéité des variances. Par contre, il en est différemment lorsque les échantillons sont de tailles différentes: sur le long terme, la probabilité de rejeter l'hypothèse nulle avec ce test est supérieure aux attentes théoriques lorsque le plus petit échantillon est extrait de la population ayant la plus grande variance, et est inférieure aux attentes théoriques lorsque le plus petit échantillon est extrait de la population ayant la plus petite variance. Au contraire, le test $t$ de Welch ne dépend pas de la condition d'homogénéité des variances. Il est souvent recommandé aux chercheurs de tester préalablement la condition d'homogénéité des variances, via un test de Levene par exemple, et ensuite d'utiliser soit le test $t$ de Student soit le test $t$ de Welch, suivant que cette condition soit ou non respectée. Cependant, dans la mesure où la condition d'homogénéité des variances est plus souvent l'exception que la norme et qu'il est parfois très difficile (voire impossible) de détecter les écarts à cette condition à travers des tests, nous recommandons l'usage du test $t$ de Welch par défaut, au moins lorsque les échantillons sont de taille différente. En effet, ce test est pratiquement aussi puissant que le test $t$ de Student lorsque la condition d'homogénéité des variances est respectée, et contrôle bien mieux les taux d'erreur de type I et II lorsqu'elle ne l'est pas. Par ailleurs, il est disponible dans presque tous les logiciels statistiques courants ($R$, Minitab, Jamovi, SPSS, etc.). Dans la mesure où l'ANOVA $F$ de Fisher est une généralisation du test $t$ de Student\footnote{L'ANOVA $F$ de Fisher peut être utilisée lorsqu'on compare deux ou plus de deux échantillons indépendants sur base de leur moyenne. Lorsqu'on compare exactement deux groupes, le test $t$ de Student et l'ANOVA $F$ de Fisher sont strictement équivalents. En effet, ils entretiennent la relation mathématique suivante: $F(1,x) = t^2(x)$.}, il n'est pas surprenant que nos simulations relatives à l'ANOVA $F$ de Fisher amènent à des constats semblables à ceux obtenus sur base de nos simulations relativement au test $t$ de Student. En outre, ces simulations nous ont permis de faire deux constats supplémentaires: d'abord, lorsqu'on compare plus de deux groupes, l'ANOVA $F$ de Fisher est affectée par la présence d'hétérogénéité des variances, même lorsque tous les échantillons sont de tailles identiques. Dans ce cas, le test devient plus liberal, ce qui signifie qu'il amène à rejeter l'hypothèse nulle plus souvent qu'attendu théoriquement, sur le long terme. Ensuite, plus le nombre d'échantillons comparés est important, plus le test est affecté par les violations de la condition d'homogénéité des variances. En cas d'homogénéité des variances, le test $W$ de Welch est très légèrement inférieur aux tests $F^*$ de Brown-Forsythe que $F$ de Fisher, tant en termes de contrôle des erreurs de type I et II qu'en termes de consistances entre les puissances théoriques et observées. Par contre, il leur est bien supérieur en cas d'hétérogénéité des variances. Pour les mêmes raisons que celles qui nous amènent à privilégier le test $t$ de Welch par défaut, nous recommandons de privilégier systématiquement le test $W$ de Welch lorsqu'on compare plus de deux groupes de sujets indépendants sur base de leur moyenne. Tout comme le test $t$ de Welch, le test $W$ de Welch est disponible dans la plupart des logiciels statistiques fréquemment utilisés par les chercheurs en psychologie ($R$, Minitab, Jamovi, SPSS, etc.). En ce qui concerne la mesure $d$ de Cohen, nous avons mis deux éléments principaux en évidence. D'abord, il s'agit d'une mesure toujours biaisée, mêmelorsque toutes les conditions dont elle dépend sont respectées. Heureusement, une transformation de cette mesure existe telle que le biais devient nul lorsque la condition de normalité des résidus est respectée. Cette transformation a été proposée par Hedges et porte dès lors son nom: la mesure $g$ de Hedges. Ensuite, une violation de la condition d'homogénéité des variances amènera à une forte augmentation de la variance des estimateurs $d$ de Cohen et $g$ de Hedges, même lorsque les deux échantillons sont de taille identique. Différents estimateurs ont été proposés dans la littérature en vue de remplacer le $d$ de Cohen (et le $g$ de Hedges) en cas de violation de la condition d'homogénéité des variances. Parmis ceux-ci, on retrouve fréquemment le $d$ de Glass, qui peut être transformé de sorte à obtenir le $g$ de Glass, théoriquement non biaisé lorsque les résidus se distribuent normalement. Nos simulations ont révélé que la variance du $g$ de Glass de même que son biais (lorsque les résidus sont extraits de populations qui ne se distribuent pas normalement) dépendent fortement de paramètres que l'on ne peut contrôler, ce qui nous amène à décourager l'usage de cette mesure. Dans la litérature, on retrouve également la mesure $d$ de Shieh, qui entretient une relation mathématique directe avec le $t$ de Welch, ainsi que la mesure $d^*$ de Cohen qui, contrairement au $d$ de Cohen classique, implique le calcul de la moyenne *non poolée* des variances de chaque groupe. De même que pour les estimateurs précédemment cités, il est possible de transformer ces mesures en vue de supprimer le biais lorsque la condition de normalité des résidus est respectée. Cela donne respectivement lieu aux mesures $g^*$ de Hedges et $g$ de Shieh. Grâce à nos simulations, nous avons révélé que le $g^*$ de Hedges est supérieur au $g$ de Shieh, non seulement d'un point de vue inférentiel (contrairement au $g$ de Shieh, le $g^*$ de Hedges est consistant, ce qui signifie que sa variance diminue toujours lorsque les tailles d'échantillon augmentent, de même que son biais lorsque les résidus sont extraits d'une population anormale) que d'un point de vue interprétatif (sa valeur est constante, peu importe que les deux échantillons soient de taille identique ou non). Finalement, lorsqu'on compare les mesures $g$ de Hedges et $g^*$ de Hedges, on constate que le $g^*$ de Hedges n'est très légèrement inférieur au $g$ de Hedges, en termes de biais et de variance, que lorsque des échantillons de tailles différentes sont extraits de population aux variances identiques. Il est tout aussi efficace que le $g$ de Hedges lorsque tant les tailles d'échantillons que les variances de population sont identiques. De plus, il reste valide lorsque la condition d'homogénéité des variances n'est pas respectée, contrairement au $g$ de Hedges. Pour les mêmes raisons que celles qui nous amènent à privilégier les tests $t$ de Welch et $F$ de Welch par défaut, nous recommandons de privilégier systématiquement le $g^*$ de Hedges. 

Dans un deuxième temps, nous nous sommes concentrés sur la tendance des chercheurs à définir par défaut, comme hypothèse nulle, une hypothèse d'absence d'effet. Nous avons souligné que cette tendance persiste même lorsque l'objectif est de prouver une absence d'effet: c'est alors sur base d'un non rejet de l'hypothèse nulle que les chercheurs affirment pouvoir valider leur hypothèse. Pourtant, nous avons vu que ce n'est pas une stratégie adéquate puisque non seulement le test utilisé de cette manière présente de faibles propriétés asymptotiques, mais en plus, la probabilité que le test amène à conclure à l'absence d'effet augmente à mesure que l'erreur de mesure augmente. Nous avons également souligné qu'en réalité, il n'existe aucun test d'hypothèses qui permette de démontrer l'absence totale d'effet. Par contre, il est possible de démontrer qu'un effet observé ne s'éloigne pas de l'absence d'effet d'une quantité supérieure à une valeur définie (dit autrement, qu'il est *équivalent*), à condition de comprendre qu'il est théoriquement possible de définir n'importe quelle différence (ou intervalle de différences) de moyennes comme hypothèse nulle. C'est le principe sur lequel repose le TOST (Two One-Sided Tests), à travers lequel on conclut à l'équivalence à condition que l'intervalle de confiance à $(1-2\alpha)\%$ autour de l'effet étudié soit entièrement inclus à l'intérieur de la zone d'équivalence. Récemment, @blume_second-generation_2018 ont proposé un nouvel outil qui se nomme le SGPV (Second Generation P-Value) qu'ils définissent comme la proportion des valeurs de l'intervalle de confiance à $(1-\alpha)\%$  qui sont également compatibles avec l'hypothèse nulle (ou autrement dit, qui se situent à l'intérieur de la zone d'équivalence). Il nous a semblé pertinent de comparer le SPGV au TOST, dans la mesure où les deux stratégies reposent sur un principe similaire, à savoir la comparaison de l'intervalle de confiance de l'effet observé avec la zone d'équivalence. Cependant, notre comparaison n'a pas permis de mettre en évidence de réelle plus-value du SGPV par rapport au TOST. Bien que @blume_second-generation_2018 présentent le SGPV comme un outil permettant de déterminer à quel degré les données sont compatibles avec l'hypothèse d'équivalence, nous avons révélé au moins deux situations pour lesquelles cette définition ne tient pas: lorsque l'intervalle de confiance autour de l'effet observé recouvre les deux bornes de la zone d'équivalence tout en ayant une largeur moins de deux fois supérieure à celle de la zone d'équivalence, et lorsque les intervalles de confiance sont asymétriques, ce qui est le cas, par exemple, lorsqu'on étudie une corrélation $r$ de Pearson (tel que décrit dans l'article du chapitre 5) ou encore lorsqu'on étudie des mesures de taille d'effet standardisées de la famille $d$ (ces dernières ayant fait l'objet du chapitre 4). In fine, les seules situations pour lesquelles le SGPV permet de tirer une conclusion claire sont celles où sa valeur vaut exactement 0 ou 1. Or, les conclusions tirées dans ce cas sont similaires, mais moins précises, à celles que permettent de tirer le TOST. 
*Blume et ses collaborateurs ont introduit un outil qui n'apporte pas grand chose*: 
*1) les seules valeurs que l'on peut facilement interpréter, ce sont 0 et 1 (mais ces valeurs correspondent à une p-valeur de TOST respectivement > .975 ou < .025 dc ça ne fait rien de plus que le TOST lorsqu'on l'utilise d'un point de vue Neyman-Pearson, où l'on compare la p-valeur au risque alpha, et fait moins que le TOST lorsqu'on l'utilise du point de vue de Fisher car la p-valeur différencie là où le TOST vaut tj 0 ou 1)*.
*2) Il faut apporter une correction pour éviter une mauvaise interprétation quand l'IC est trop large (alors que pas besoin de correction avec le TOST). De plus, la correction exclut toute une série de situations (où l'IC chevauche les deux bornes de l'IC mais en étant moins que 2 fois plus grand que la zone d'équivalence). Et parfois, la correction apparaît quand ce n'est pas nécessaire, comme on le voit à travers la figure 13 de l'article du chapitre 5.* *3) Blume et al. sous-entendent que le SGPV permet d'éviter les correction spour comparaison multiples. Mais c'est faux, vu la correspondance parfaite entre TOST et SGPV quand il s'agit de décider si on a un soutien en faveur de l'équivalence ou pas, ça démontre bien que dans les 2 cas, on peut avoir une déformation des taux d'erreur de type I et II.*

## Apports (à faire article par article pour mettre mes idées en ordre)

### Test t de student et ANOVA de Fisher

Le principal apport des articles présentés au sein des chapitres 2 et 3 était d'ordre pédagogique. Bien que la question de l'impact des violations des conditions d'application du test $t$ de Student ait déjà été largement explorée par le passé [voir par exemple @harwell_summarizing_1992], les débats autours de cette question semblaient toujours ignorés par de nombreux chercheurs appliqués. Il nous est apparu que la litérature manquait d'articles expliquant de manière compréhensible les conséquences réelles des violations des conditions d'application des tests, en s'appuyant sur des exemples concrets et issus de la psychologie. C'est donc pour combler le fossé entre les méthodologistes et la majorité des chercheurs appliqués que nous avons écrit ces deux premiers articles. De plus, si la prise de conscience des limites d'une méthode est un premier pas très important, il est tout aussi important de savoir comment pallier ces limites, ce qui nous a motivé à fournir des recommandation concrètes. A nouveau, nous avons accordé beaucoup d'importance à la valeur pédagogique de nos recommandations: le choix de ces dernières a été fortement guidé par le désir de proposer des stratégies qui pourraient être facilement comprises et appliquées par la grande majorité des chercheurs. S'il est certain que remplacer les tests $t$ de Student et $F$ de Fisher par les tests de Welch constitue un progrès important, il est tout aussi certain que les tests de Welch ne sont pas une solution miracle à tous les problèmes. Par exemple, comme le révèle les figures de l'article présenté au sein du chapitre 3, le test de Welch est sensible à certaines violations de la condition de normalité. Entre autre, la puissance du test est altérée (c'est-à-dire qu'elle est non conforme aux attentes théoriques) lorsque les données sont extraites de distributions fortement asymétriques ou qui ont des extrêmités très denses. L'usage de tests de comparaison des moyennes trimmées, par exemple, permet de réduire fortement ce problème [voir par exemple @wilcox_results_1994; @wilcox_how_1998]\footnote{Comme il sera expliqué dans la section relative aux limites, au sein de l'article présenté dans le chapitre 2, nous avons porté un jugement trop sévère à l'égard du test de Yuen qui repose sur le principe de comparaison des moyennes trimmées. Ce jugement reposait sur une mauvaise compréhension de notre part des objectifs du test.}. Cependant, il est important de bien comprendre qu'en optant pour le test de Yuen, on modifie l'hypothèse de recherche et nous avons déjà souligné la résistance des chercheurs à l'idée de modifier la manière dont ils formulent leurs hypothèses. Il en est de même lorsqu'on opte pour un test non paramétrique. L'usage du test de Welch n'implique pas de changer de philosophie de recherche (voir Daniel dans article sur le tost: il parle à un endroit de philosophical shift, m'inspirer de la formulation) ni de repenser la manière de définir les hypothèses. Nous n'ignorons pas pour autant l'importance de le faire, et c'est pourquoi nous avons ouvert la porte sur ces tests, en précisant la nécessité de réaliser des analyses descriptives et de réaliser des tests adéquats si l'on suspecte que d'autres paramètres que la moyenne sont influencés par le traitement expérimental.

Expliquer les principes qui ont guidé le choix de nos recommandations:
(1) Les chercheurs appliqués sont noyés sous les articles dans leur domaine d'expertise si bien que cela limite le temps dont ils disposent pour se consacrer aux articles méthodologiques [@mills_quantitative_2010];   --> donc il faut qu'il soit le plus simple possible. 
(2) Les chercheurs tendent à privilégier les méthodes qui sont proposées par défaut dans des logiciels de clique bouton (comme SPSS). C'est en tout cas ce que dit @counsell_reporting_2017 dans le contexte de la gestion des données manquantes (mais je crois que c'est vrai pour tout). Or, Welch l'est dans presque tous (même parfois proposé par défaut).

Puisque nous souhaitions nous adresser à tous les chercheurs en psychologie, nous avons mis des démarches en oeuvre en vue d'assurer une grande diffusion et visibilité de cet article:
1) Avant que l'article ne soit accepté pour publication, nous avons diffusé un preprint sur les réseaux sociaux (Facebook, Twitter...)
2) Nous avons soumis l'article dans une revue Open Access (*l'International Review of Social Psychology*).       
3) Nous avons rendu disponible en ligne gratuitement et en open access tous les scripts de nos simulations et analyses. Nous l'avons fait dans un premier temps en utilisant la plateforme de l'OSF (Open Science Framework) et ensuite via Github (à définir?)
Ces démarches semblent avoir porté leur fruit, compte tenu du taux de citation de l'article (proche de 400 citations).

### d de Cohen

Apport théorique: m'inspirer de tous les échanges avec Cumming. J'ai en gros bien montré les inconvénients du d de Glass. Et le faire en toute transparencea permis des échanges ultra utiles avec Cumming (en termes de réflexion liée à l'interprétabilité, etc.)

Apport pratique: Mettre toute la partie où je signale qu'un article méthodo suffit raremetn à lui seul. Dans les deux articles d'avant, il n'étai tpas nécessaire de créer des outils dans la mesure où le Welch est déjà dans pleins de logiciels très utilisés. Mais ce n'est pas le cas pour le g* de Cohen. D'où les packages et Shiny App. 

### TOST vs. SGPV

Apport essentiellement théorique puisqu'on critique le SGPV. Il n'y a pas eu vraiment d'apport pratique puisque le TOST a déjà fait l'objet d'outils concrets par le premier auteur de l'article (Lakens).