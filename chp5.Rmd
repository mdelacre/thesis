---
title: " "
output: 
  papaja::apa6_pdf:
    includes:
      extra_dependencies: ["float"]

header-includes:
  - \usepackage{float}
  - \usepackage{sectsty}
---

# Chapitre 5: les tests d'équivalence

## Introduction du chapitre

Lorsqu'on applique un test d'hypothèse, l'hypothèse nulle la plus couramment définie est celle d'absence d'effet ou de différence entre les groupes [@nickerson_null_2000]. Il arrive également parfois que les chercheurs définissent un intervalle de valeur comme hypothèse nulle, mais le plus souvent, cet intervalle est borné par la valeur 0 [@nickerson_null_2000], on parle alors d'hypothèse unilatérale. Avec cette stratégie, le rejet de l'hypothèse nulle constitue un soutien en faveur de la présence d'un effet non nul. Par contre, le non rejet de l'hypothèse nulle ne peut être interprété comme un soutien en faveur de l'absence d'effet. Il arrive pourtant fréquemment que des chercheurs fassent cette erreur d'interprétation. @finch_reporting_2001, par exemple, ont reporté que parmis 150 articles publiés entre 1940 et 1999 dans le *JAP* (*Journal of Applied Psychology*), 38% interprétaient un résultat non significatif comme une acceptation de l'hypothès nulle. Plus récemment, @lakens_equivalence_2017 a noté que l'expression "pas d'effet" a été utilisée dans 108 articles publié dans *Social Psychological and Personality Science* avant août 2016 et que dans presque tous les cas, c'était sur base du non rejet de l'hypothèse nulle que cette conclusion était tirée. 

(1) A travers ce chapitre, notre premier objectif sera d'expliquer pourquoi le non-rejet de l'hypothèse nulle ne peut être assimilé à une acceptation de l'hypothèse nulle. (2) Nous expliquerons ensuite le principe des tests d'équivalence. (3) Nous concluerons ce chapitre sur un article dans lequel nous comparer les tests d'équivalence à une stratégie récement développée par Blume (le $SGPV$).

## Quand veut-on montrer une absence d'effet?

Il arrive que des chercheurs souhaitent obtenir un soutien en faveur d'une absence d'effet. A titre d'illustration, @goertzen_detecting_2010 évoquent la situation où un chercheur désire écarter de potentielles covariables de leur analyse, en démontrant préalablement que ces variables ne sont pas corrélées à la variable dépendante. ESSAYER DE TROUVER ENCORE UN EXEMPLE. Or, on constate que très souvent, 

## (1) Différence entre NRH0 et AH0

Le premier problème avec la stratégie traditionnelle est le fait que conclure au non rejet de l'hypothèse nulle ne signifie pas que l'on puisse accepter l'hypothèse nulle. En pratique, même lorsqu'une vraie différence non nulle existe entre les moyennes de population, il arrive que l'on soit amenés à conclure au non rejet de l'hypothèse nulle. *Dans le cas idéal où nous aurions un échantillon de taille suffisante pour détecter l'effet étudié avec suffisamment de puissance, ce taux resterait assez faible bien que non nul. Et dans la mesure où souvent, la puissance dans les études est assez basses, ce taux peut encore augmenter. (retrouver projet de recherche pour décrire un peu ça sur base de quelques références)*. Afin de l'illustrer, nous avons réalisé des simulations Monte Carlo pour un ensemble de 70 scénarios qui diffèrent en fonction de la taille des échantillons ($n_j$) et de la différence entre les moyennes des deux populations dont sont extraits les échantillons ($\mu_1-\mu_2$; voir Table 1). Pour chaque scénario, à 5000 reprises, nous avons généré une paire d'échantillons, réalisé un test $t$ de Student pour échantillons indépendants et extrait la $p$-valeur du test, de sorte à obtenir au final 5000 $p$-valeur par scénario. Les résultats qui apparaissent au sein de la table 1 correspondent, pour chaque scénario, à la proportion de $p$-valeurs *supérieures* à .05, le risque alpha communément accepté par les chercheurs \footnote{Cette proportion est ce qu'on appelle communément $\beta$, le taux d'erreur de type II.} [référence?]. Etant donné que dans tous les scénarios envisagés, la différence entre les moyennes de population est non nulle, on souhaiterait sur le long terme conclure le plus souvent possible au rejet de l'hypothèse nulle. Dit autrement, on souhaiterait que $\beta$ soit le plus faible possible. Pourtant, il s'avère très élevé pour certains scénarios. Par exemple, avec 10 sujets par groupes et une taille d'effet standardisée de .1, on conclut dans près de 95% des cas au non rejet de l'hypothèse nulle. On peut constater qu'avec une telle taille d'effet, même avec 200 sujets par groupes, on est encore amenés à conclure au non rejet de l'hypothèse nulle plus de 8 fois sur 10.

Le deuxième problème avec l'approche traditionnelle est que la probabilité de détecter l'absence d'effet va diminuer non seulement (1) quand la taille des échantillons augmente, mais également (2) quand l'erreur (la variabilité des scores au sein de chaque groupe) va augmenter [Meyners, voir power point]. On se retrouve alors dans la situation paradoxale où la probabilité de démontrer l'absence d'effet augmente lorsque des petits échantillons sont associés à une grande erreur de mesure [Meyners].  

Un test a de bonnes propriétés asymptotiques si sa puissance augmente à mesure que la taille des échantillons grandit. Or, plus les échantillons sont grands, *moins* il est probable de conclure au non rejet de l'hypothèse nulle (soit en l'occurence, ce que les chercheurs tentent de démontrer lorsqu'ils postulent en faveur d'une absence d'effet). Ils se retrouvent alors dans une situation paradoxale où plus l'échantillon est grand, moins ils ont de chance de démontrer ce qu'ils veulent démontrer. 

```{r "simu", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Illustration/Illustration.png")
```
Table: Proportion de $p$-valeurs supérieures à .05 ($\beta$) en fonction de $n_j$ et $\mu_1-\mu_2$.
*Note*. Pour chaque scénario, les deux échantillons sont toujours de même taille ($n_j=n_1=n_2$) et sont extraits de populations se distribuant normalement et ayant la même variance ($\sigma_1=\sigma_2=\sigma$). La moyenne de la première population ($\mu_1$) vaut systématiquement 0, et celle de la deuxième population ($\mu_2$) varie de sorte à obtenir la différence de moyenne $\mu_1-\mu_2$ désirée. Par ailleurs, $\sigma$ vaut systématiquement 1, si bien que la différence de moyenne brute est égale au $\delta$ de Cohen. 



moderate. With a sample size of N ¼ 10, approximately 75% of sample correlation values (in absolute value) exceed r ¼ :1, 40% exceed r ¼ :3, and even 15% exceed r ¼ :5. With larger sample sizes there is still substantial variability in correlation coefficients. With a sample size of N ¼ 20, approximately 40% of sample correlation values exceed r ¼ :2, and 20% exceed r ¼ :3. Even with a sample size of N ¼ 100, more than 30% of sample correlation values exceed r ¼ :1.




```{r "tauxbeta", echo=FALSE}

#simu_beta <- function(n){

#  mudiff <- seq(.1,1.9,.2)
#  NRH0 <- NULL
  
#  for(j in seq_len(length(mudiff))){

#    m2 <- mudiff[j]  
#    t <- NULL
#    pval <- NULL
    
#    for (i in seq_len(5000)){
#      G1 <- rnorm(n,0,1)
#      G2 <- rnorm(n,m2,1)
#      res <- t.test(G1,G2,var.equal=TRUE)
#      t <- c(t, res$statistic)  
#      pval <- c(pval,res $p.value)  
#    }

#    NRH0 <- c(NRH0,sum(pval>.05)/length(pval))
    
#}

# return(round(NRH0,3))
 
  
#}

#S1 <- simu_beta(10)
#S2 <- simu_beta(15)
#S3 <- simu_beta(20)
#S4 <- simu_beta(25)
#S5 <- simu_beta(50)
#S6 <- simu_beta(100)
#S7 <- simu_beta(200)

#df <- rbind(S1,S2,S3,S4,S5,S6,S7)
#colnames(df)=seq(.1,1.9,.2)
#rownames(df)=c(10,15,20,25,50,100,200)

#write.table(df,"df.txt",sep=";",dec=",")
```

-Au mieux, le non rejet de l'hypothèse nulle nous montre que les données ne sont pas incompatibles avec l'hypothèse nulle, mais cela ne veut en aucun cas dire qu'elles ne sont compatibles avec aucune autres hypothèse!  


## Principe du test d'équivalence

## Morceau qui servira peut-être (ou pas)

D'après @lakens_practical_2021, un test d'hypothèse (selon l'approche de Nayman-Pearson) vaut la peine à 2 conditions:  
1) que l'hypothèse nulle soit assez plausible pour que son rejet puisse surprendre au moins certains;  
2) le chercheur veut appliquer une procédure méthodol qui l'autorise à prendre des décisions quant à la manière d'agir, tout en contrôlant le taux d'erreur. Agir peut vouloir dire: adopter un traitement, une politique, une intervention, ou abandonner un domaine de rechercher, modifier une manipulation, ou de faire un certain type de déclaration ou revendication.  
*One of the most widely suggested improvements of the use of p values is to replace null-ypothesis tests (where the goal is to reject ann effect of exactly 0) with tests of range predictions (where the goal is to reject effects that fall outside of the range of effects that is predicted or considered practically important) [@lakens_practical_2021]. 

Un autre argument en défaveur de la p-valeur est la tendance des chercheurs à interpréter un effet NS comme l'acceptation de l'hypothèse nulle (Schmidt, 1996, cité par Harris, 1997). Une fois encore, l'usage des tailles d'effet peut aider à cette fin, non pas en "remplaçant" les tests d'hypothèses, mais en les complétant. --> Tests d'équivalence. 













```{r "chp5p1", fig.align='center', fig.cap=NULL,echo=FALSE,out.width="92%"}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-1.png")
```

```{r "chp5p2", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-2.png")
```

```{r "chp5p3", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-3.png")
```

```{r "chp5p4", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-4.png")
```

```{r "chp5p5", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-5.png")
```

```{r "chp5p6", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-6.png")
```

```{r "chp5p7", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-7.png")
```

```{r "chp5p8", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-8.png")
```

```{r "chp5p9", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-9.png")
```

```{r "chp5p10", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-10.png")
```

```{r "chp5p11", fig.align='center', fig.cap=NULL,echo=FALSE}
knitr::include_graphics("C:/Users/Admin/OneDrive/Documents/Github projects/thesis/Chapitre 5/Chapitre 5-10.png")
```


